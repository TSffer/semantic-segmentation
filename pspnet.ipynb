{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pspnet.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TSffer/semantic-segmentation/blob/master/pspnet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "59lIGzpMHfnd",
        "colab_type": "code",
        "outputId": "1bb61616-d02d-4373-9ccc-f3b6bd6b7349",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        }
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "from keras.backend.tensorflow_backend import  set_session\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if(device_name != '/device:GPU:0'):\n",
        "     raise SystemError(\"GPU device not found\")\n",
        "print('Found GPU at: {}'.format(device_name))\n",
        "\n",
        "config = tf.ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "config.log_device_placement = True\n",
        "\n",
        "sess = tf.Session(config=config)\n",
        "\n",
        "set_session(sess)\n",
        "\n",
        "from keras.models import load_model\n",
        "from types import MethodType\n",
        "from keras.models import *\n",
        "from keras.layers import *\n",
        "import keras.backend as K\n",
        "from keras import layers\n",
        "from keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "from tensorboardcolab import TensorBoardColab, TensorBoardColabCallback\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import glob\n",
        "import itertools\n",
        "import os\n",
        "import random\n",
        "import six\n",
        "import cv2\n",
        "import argparse\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "\n",
        "import datetime\n",
        "%load_ext tensorboard\n",
        "\n",
        "!rm -rf ./logs/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n",
            "Device mapping:\n",
            "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
            "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
            "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
            "\n",
            "The tensorboard extension is already loaded. To reload it, use:\n",
            "  %reload_ext tensorboard\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMDYlhXPj83q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "IMAGE_ORDERING_CHANNELS_LAST = \"channels_last\"\n",
        "IMAGE_ORDERING_CHANNELS_FIRST = \"channels_first\"\n",
        "\n",
        "# Default IMAGE_ORDERING = channels_last\n",
        "IMAGE_ORDERING = IMAGE_ORDERING_CHANNELS_LAST"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UVqqJiQiWoyE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "try:\n",
        "    from tqdm import tqdm\n",
        "except ImportError:\n",
        "    print(\"tqdm not found, disabling progress bars\")\n",
        "    def tqdm(iter):\n",
        "        return iter\n",
        "\n",
        "DATA_LOADER_SEED = 0\n",
        "\n",
        "random.seed(DATA_LOADER_SEED)\n",
        "class_colors = [(random.randint(0, 255), random.randint(\n",
        "    0, 255), random.randint(0, 255)) for _ in range(5000)]\n",
        "\n",
        "\n",
        "class DataLoaderError(Exception):\n",
        "    pass\n",
        "\n",
        "def get_pairs_from_paths(images_path, segs_path, ignore_non_matching=False):\n",
        "    \"\"\" Find all the images from the images_path directory and\n",
        "        the segmentation images from the segs_path directory\n",
        "        while checking integrity of data \"\"\"\n",
        "\n",
        "    ACCEPTABLE_IMAGE_FORMATS = [\".jpg\", \".jpeg\", \".png\"]\n",
        "    ACCEPTABLE_SEGMENTATION_FORMATS = [\".png\"]\n",
        "\n",
        "    image_files = []\n",
        "    segmentation_files = {}\n",
        "\n",
        "    for dir_entry in os.listdir(images_path):\n",
        "        if os.path.isfile(os.path.join(images_path, dir_entry)) and \\\n",
        "                os.path.splitext(dir_entry)[1] in ACCEPTABLE_IMAGE_FORMATS:\n",
        "            file_name, file_extension = os.path.splitext(dir_entry)\n",
        "            image_files.append((file_name, file_extension, os.path.join(images_path, dir_entry)))\n",
        "\n",
        "    for dir_entry in os.listdir(segs_path):\n",
        "        if os.path.isfile(os.path.join(segs_path, dir_entry)) and \\\n",
        "                os.path.splitext(dir_entry)[1] in ACCEPTABLE_SEGMENTATION_FORMATS:\n",
        "            file_name, file_extension = os.path.splitext(dir_entry)\n",
        "            if file_name in segmentation_files:\n",
        "                raise DataLoaderError(\"Segmentation file with filename {0} already exists and is ambiguous to resolve with path {1}. Please remove or rename the latter.\".format(file_name, os.path.join(segs_path, dir_entry)))\n",
        "            segmentation_files[file_name] = (file_extension, os.path.join(segs_path, dir_entry))\n",
        "\n",
        "    return_value = []\n",
        "    # Match the images and segmentations\n",
        "    for image_file, _, image_full_path in image_files:\n",
        "        if image_file in segmentation_files:\n",
        "            return_value.append((image_full_path, segmentation_files[image_file][1]))\n",
        "        elif ignore_non_matching:\n",
        "            continue\n",
        "        else:\n",
        "            # Error out\n",
        "            raise DataLoaderError(\"No corresponding segmentation found for image {0}.\".format(image_full_path))\n",
        "\n",
        "    return return_value\n",
        "\n",
        "\n",
        "def get_image_array(image_input, width, height, imgNorm=\"sub_mean\",\n",
        "                  ordering='channels_first'):\n",
        "    \"\"\" Load image array from input \"\"\"\n",
        "\n",
        "    if type(image_input) is np.ndarray:\n",
        "        # It is already an array, use it as it is\n",
        "        img = image_input\n",
        "    elif  isinstance(image_input, six.string_types)  :\n",
        "        if not os.path.isfile(image_input):\n",
        "            raise DataLoaderError(\"get_image_array: path {0} doesn't exist\".format(image_input))\n",
        "        img = cv2.imread(image_input, 1)\n",
        "    else:\n",
        "        raise DataLoaderError(\"get_image_array: Can't process input type {0}\".format(str(type(image_input))))\n",
        "\n",
        "    if imgNorm == \"sub_and_divide\":\n",
        "        img = np.float32(cv2.resize(img, (width, height))) / 127.5 - 1\n",
        "    elif imgNorm == \"sub_mean\":\n",
        "        img = cv2.resize(img, (width, height))\n",
        "        img = img.astype(np.float32)\n",
        "        img[:, :, 0] -= 103.939\n",
        "        img[:, :, 1] -= 116.779\n",
        "        img[:, :, 2] -= 123.68\n",
        "        img = img[:, :, ::-1]\n",
        "    elif imgNorm == \"divide\":\n",
        "        img = cv2.resize(img, (width, height))\n",
        "        img = img.astype(np.float32)\n",
        "        img = img/255.0\n",
        "\n",
        "    if ordering == 'channels_first':\n",
        "        img = np.rollaxis(img, 2, 0)\n",
        "    return img\n",
        "\n",
        "\n",
        "def get_segmentation_array(image_input, nClasses, width, height, no_reshape=False):\n",
        "    \"\"\" Load segmentation array from input \"\"\"\n",
        "\n",
        "    seg_labels = np.zeros((height, width, nClasses))\n",
        "\n",
        "    if type(image_input) is np.ndarray:\n",
        "        # It is already an array, use it as it is\n",
        "        img = image_input\n",
        "    elif isinstance(image_input, six.string_types) :\n",
        "        if not os.path.isfile(image_input):\n",
        "            raise DataLoaderError(\"get_segmentation_array: path {0} doesn't exist\".format(image_input))\n",
        "        img = cv2.imread(image_input, 1)\n",
        "    else:\n",
        "        raise DataLoaderError(\"get_segmentation_array: Can't process input type {0}\".format(str(type(image_input))))\n",
        "\n",
        "    img = cv2.resize(img, (width, height), interpolation=cv2.INTER_NEAREST)\n",
        "    img = img[:, :, 0]\n",
        "\n",
        "    for c in range(nClasses):\n",
        "        seg_labels[:, :, c] = (img == c).astype(int)\n",
        "\n",
        "    if not no_reshape:\n",
        "        seg_labels = np.reshape(seg_labels, (width*height, nClasses))\n",
        "\n",
        "    return seg_labels\n",
        "\n",
        "\n",
        "def verify_segmentation_dataset(images_path, segs_path, n_classes, show_all_errors=False):\n",
        "    try:\n",
        "        img_seg_pairs = get_pairs_from_paths(images_path, segs_path)\n",
        "        if not len(img_seg_pairs):\n",
        "            print(\"Couldn't load any data from images_path: {0} and segmentations path: {1}\".format(images_path, segs_path))\n",
        "            return False\n",
        "\n",
        "        return_value = True\n",
        "        for im_fn, seg_fn in tqdm(img_seg_pairs):\n",
        "            img = cv2.imread(im_fn)\n",
        "            seg = cv2.imread(seg_fn)\n",
        "            # Check dimensions match\n",
        "            if not img.shape == seg.shape:\n",
        "                return_value = False\n",
        "                print(\"The size of image {0} and its segmentation {1} doesn't match (possibly the files are corrupt).\".format(im_fn, seg_fn))\n",
        "                if not show_all_errors:\n",
        "                    break\n",
        "            else:\n",
        "                max_pixel_value = np.max(seg[:, :, 0])\n",
        "                if max_pixel_value >= n_classes:\n",
        "                    return_value = False\n",
        "                    print(\"The pixel values of the segmentation image {0} violating range [0, {1}]. Found maximum pixel value {2}\".format(seg_fn, str(n_classes - 1), max_pixel_value))\n",
        "                    if not show_all_errors:\n",
        "                        break\n",
        "        if return_value:\n",
        "            print(\"Dataset verified! \")\n",
        "        else:\n",
        "            print(\"Dataset not verified!\")\n",
        "        return return_value\n",
        "    except DataLoaderError as e:\n",
        "        print(\"Found error during data loading\\n{0}\".format(str(e)))\n",
        "        return False\n",
        "\n",
        "def image_segmentation_generator(images_path, segs_path, batch_size,\n",
        "                                 n_classes, input_height, input_width,\n",
        "                                 output_height, output_width,\n",
        "                                 do_augment=False):\n",
        "\n",
        "    img_seg_pairs = get_pairs_from_paths(images_path, segs_path)\n",
        "    random.shuffle(img_seg_pairs)\n",
        "    zipped = itertools.cycle(img_seg_pairs)\n",
        "\n",
        "    while True:\n",
        "        X = []\n",
        "        Y = []\n",
        "        for _ in range(batch_size):\n",
        "            im, seg = next(zipped)\n",
        "\n",
        "            im = cv2.imread(im, 1)\n",
        "            seg = cv2.imread(seg, 1)\n",
        "\n",
        "            if do_augment:\n",
        "                im, seg[:, :, 0] = augment_seg(im, seg[:, :, 0])\n",
        "\n",
        "            X.append(get_image_array(im, input_width,\n",
        "                                   input_height, ordering=IMAGE_ORDERING))\n",
        "            Y.append(get_segmentation_array(\n",
        "                seg, n_classes, output_width, output_height))\n",
        "\n",
        "        yield np.array(X), np.array(Y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TCdGAuoZkbZD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def find_latest_checkpoint(checkpoints_path, fail_safe=True):\n",
        "\n",
        "    def get_epoch_number_from_path(path):\n",
        "        return path.replace(checkpoints_path, \"\").strip(\".\")\n",
        "\n",
        "    # Get all matching files\n",
        "    all_checkpoint_files = glob.glob(checkpoints_path + \".*\")\n",
        "    # Filter out entries where the epoc_number part is pure number\n",
        "    all_checkpoint_files = list(filter(lambda f: get_epoch_number_from_path(f).isdigit(), all_checkpoint_files))\n",
        "    if not len(all_checkpoint_files):\n",
        "        # The glob list is empty, don't have a checkpoints_path\n",
        "        if not fail_safe:\n",
        "            raise ValueError(\"Checkpoint path {0} invalid\".format(checkpoints_path))\n",
        "        else:\n",
        "            return None\n",
        "\n",
        "    # Find the checkpoint file with the maximum epoch\n",
        "    latest_epoch_checkpoint = max(all_checkpoint_files, key=lambda f: int(get_epoch_number_from_path(f)))\n",
        "    return latest_epoch_checkpoint\n",
        "\n",
        "\n",
        "def train(model,\n",
        "          train_images,\n",
        "          train_annotations,\n",
        "          input_height=None,\n",
        "          input_width=None,\n",
        "          n_classes=None,\n",
        "          verify_dataset=True,\n",
        "          checkpoints_path=None,\n",
        "          epochs=5,\n",
        "          batch_size=2,\n",
        "          validate=False,\n",
        "          val_images=None,\n",
        "          val_annotations=None,\n",
        "          val_batch_size=2,\n",
        "          validation_steps=2,\n",
        "          auto_resume_checkpoint=False,\n",
        "          load_weights=None,\n",
        "          steps_per_epoch=512,\n",
        "          optimizer_name='adam'\n",
        "          ):\n",
        "    \n",
        "    result=None\n",
        "    tb = TensorBoard(log_dir='logs',write_graph=True)\n",
        "    mc = ModelCheckpoint(mode='max',filepath='/content/drive/My Drive/checkpointsPsPNet/resnet50_pspnet.1', monitor='acc',save_best_only='True',save_weights_only='True', verbose=1)\n",
        "    es = EarlyStopping(mode='min',monitor='val_loss',patience=50, verbose=1)\n",
        "    callbacks = [tb, mc, es]\n",
        "\n",
        "    # check if user gives model name instead of the model object\n",
        "    if isinstance(model, six.string_types):\n",
        "        # create the model from the name\n",
        "        assert (n_classes is not None), \"Please provide the n_classes\"\n",
        "        if (input_height is not None) and (input_width is not None):\n",
        "            model = model_from_name[model](\n",
        "                n_classes, input_height=input_height, input_width=input_width)\n",
        "        else:\n",
        "            model = model_from_name[model](n_classes)\n",
        "\n",
        "    n_classes = model.n_classes\n",
        "    input_height = model.input_height\n",
        "    input_width = model.input_width\n",
        "    output_height = model.output_height\n",
        "    output_width = model.output_width\n",
        "\n",
        "    if validate:\n",
        "        assert val_images is not None\n",
        "        assert val_annotations is not None\n",
        "\n",
        "    if optimizer_name is not None:\n",
        "        model.compile(loss='categorical_crossentropy',\n",
        "                      optimizer=optimizer_name,\n",
        "                      metrics=['accuracy'])\n",
        "\n",
        "    if checkpoints_path is not None:\n",
        "        with open(checkpoints_path+\"_config.json\", \"w\") as f:\n",
        "            json.dump({\n",
        "                \"model_class\": model.model_name,\n",
        "                \"n_classes\": n_classes,\n",
        "                \"input_height\": input_height,\n",
        "                \"input_width\": input_width,\n",
        "                \"output_height\": output_height,\n",
        "                \"output_width\": output_width\n",
        "            }, f)\n",
        "\n",
        "    if load_weights is not None and len(load_weights) > 0:\n",
        "        print(\"Loading weights from \", load_weights)\n",
        "        model.load_weights(load_weights)\n",
        "\n",
        "    if auto_resume_checkpoint and (checkpoints_path is not None):\n",
        "        latest_checkpoint = find_latest_checkpoint(checkpoints_path)\n",
        "        if latest_checkpoint is not None:\n",
        "            print(\"Loading the weights from latest checkpoint \",\n",
        "                  latest_checkpoint)\n",
        "            model.load_weights(latest_checkpoint)\n",
        "\n",
        "    if verify_dataset:\n",
        "        print(\"Verifying training dataset\")\n",
        "        verified = verify_segmentation_dataset(train_images, train_annotations, n_classes)\n",
        "        assert verified\n",
        "        if validate:\n",
        "            print(\"Verifying validation dataset\")\n",
        "            verified = verify_segmentation_dataset(val_images, val_annotations, n_classes)\n",
        "            assert verified\n",
        "\n",
        "    train_gen = image_segmentation_generator(\n",
        "        train_images, train_annotations,  batch_size,  n_classes,\n",
        "        input_height, input_width, output_height, output_width)\n",
        "\n",
        "    if validate:\n",
        "        val_gen = image_segmentation_generator(\n",
        "            val_images, val_annotations,  val_batch_size,\n",
        "            n_classes, input_height, input_width, output_height, output_width)\n",
        "\n",
        "    if not validate:\n",
        "        #for ep in range(epochs):\n",
        "            #print(\"Starting Epoch \", ep)\n",
        "        result=model.fit_generator(train_gen, steps_per_epoch, epochs=epochs,callbacks=callbacks,verbose=1)\n",
        "            #if checkpoints_path is not None:\n",
        "        model.save_weights(checkpoints_path + \".\" + '1', overwrite=True)\n",
        "                #print(\"saved \", checkpoints_path + \".model.\" + str(ep))\n",
        "            #print(\"Finished Epoch\", ep)\n",
        "    else:\n",
        "        #for ep in range(epochs):\n",
        "            #print(\"Starting Epoch \", ep)\n",
        "        result=model.fit_generator(train_gen, steps_per_epoch,validation_data=val_gen,\n",
        "                                   validation_steps=validation_steps,  epochs=epochs,callbacks=callbacks,verbose=1)\n",
        "            #if checkpoints_path is not None:\n",
        "        model.save_weights(checkpoints_path + \".\" + '1', overwrite=True)\n",
        "                #print(\"saved \", checkpoints_path + \".model.\" + str(ep))\n",
        "           # print(\"Finished Epoch\", ep)\n",
        "    return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lwx7Zs_-mDcf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPS = 1e-12\n",
        "\n",
        "\n",
        "def get_iou(gt, pr, n_classes):\n",
        "    class_wise = np.zeros(n_classes)\n",
        "    for cl in range(n_classes):\n",
        "        intersection = np.sum((gt == cl)*(pr == cl))\n",
        "        union = np.sum(np.maximum((gt == cl), (pr == cl)))\n",
        "        iou = float(intersection)/(union + EPS)\n",
        "        class_wise[cl] = iou\n",
        "    return class_wise"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sMC7lvhx0Iwq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "random.seed(DATA_LOADER_SEED)\n",
        "\n",
        "def model_from_checkpoint_path(checkpoints_path):\n",
        "\n",
        "    assert (os.path.isfile(checkpoints_path+\"_config.json\")\n",
        "            ), \"Checkpoint not found.\"\n",
        "    model_config = json.loads(\n",
        "        open(checkpoints_path+\"_config.json\", \"r\").read())\n",
        "    latest_weights = find_latest_checkpoint(checkpoints_path)\n",
        "    assert (latest_weights is not None), \"Checkpoint not found.\"\n",
        "    model = model_from_name[model_config['model_class']](\n",
        "        model_config['n_classes'], input_height=model_config['input_height'],\n",
        "        input_width=model_config['input_width'])\n",
        "    print(\"loaded weights \", latest_weights)\n",
        "    model.load_weights(latest_weights)\n",
        "    return model\n",
        "\n",
        "\n",
        "def predict(model=None, inp=None, out_fname=None, checkpoints_path=None):\n",
        "\n",
        "    if model is None and (checkpoints_path is not None):\n",
        "        model = model_from_checkpoint_path(checkpoints_path)\n",
        "\n",
        "    assert (inp is not None)\n",
        "    assert((type(inp) is np.ndarray) or isinstance(inp, six.string_types)\n",
        "           ), \"Inupt should be the CV image or the input file name\"\n",
        "\n",
        "    if isinstance(inp, six.string_types):\n",
        "        inp = cv2.imread(inp)\n",
        "\n",
        "    assert len(inp.shape) == 3, \"Image should be h,w,3 \"\n",
        "    orininal_h = inp.shape[0]\n",
        "    orininal_w = inp.shape[1]\n",
        "\n",
        "    output_width = model.output_width\n",
        "    output_height = model.output_height\n",
        "    input_width = model.input_width\n",
        "    input_height = model.input_height\n",
        "    n_classes = model.n_classes\n",
        "\n",
        "    x = get_image_array(inp, input_width, input_height, ordering=IMAGE_ORDERING)\n",
        "    pr = model.predict(np.array([x]))[0]\n",
        "    pr = pr.reshape((output_height,  output_width, n_classes)).argmax(axis=2)\n",
        "\n",
        "    seg_img = np.zeros((output_height, output_width, 3))\n",
        "    colors = class_colors\n",
        "\n",
        "    for c in range(n_classes):\n",
        "        seg_img[:, :, 0] += ((pr[:, :] == c)*(colors[c][0])).astype('uint8')\n",
        "        seg_img[:, :, 1] += ((pr[:, :] == c)*(colors[c][1])).astype('uint8')\n",
        "        seg_img[:, :, 2] += ((pr[:, :] == c)*(colors[c][2])).astype('uint8')\n",
        "\n",
        "    seg_img = cv2.resize(seg_img, (orininal_w, orininal_h))\n",
        "\n",
        "    if out_fname is not None:\n",
        "        cv2.imwrite(out_fname, seg_img)\n",
        "\n",
        "    return pr\n",
        "\n",
        "\n",
        "def predict_multiple(model=None, inps=None, inp_dir=None, out_dir=None,\n",
        "                     checkpoints_path=None):\n",
        "\n",
        "    if model is None and (checkpoints_path is not None):\n",
        "        model = model_from_checkpoint_path(checkpoints_path)\n",
        "\n",
        "    if inps is None and (inp_dir is not None):\n",
        "        inps = glob.glob(os.path.join(inp_dir, \"*.jpg\")) + glob.glob(\n",
        "            os.path.join(inp_dir, \"*.png\")) + \\\n",
        "            glob.glob(os.path.join(inp_dir, \"*.jpeg\"))\n",
        "\n",
        "    assert type(inps) is list\n",
        "\n",
        "    all_prs = []\n",
        "\n",
        "    for i, inp in enumerate(tqdm(inps)):\n",
        "        if out_dir is None:\n",
        "            out_fname = None\n",
        "        else:\n",
        "            if isinstance(inp, six.string_types):\n",
        "                out_fname = os.path.join(out_dir, os.path.basename(inp))\n",
        "            else:\n",
        "                out_fname = os.path.join(out_dir, str(i) + \".jpg\")\n",
        "\n",
        "        pr = predict(model, inp, out_fname)\n",
        "        all_prs.append(pr)\n",
        "\n",
        "    return all_prs\n",
        "\n",
        "\n",
        "\n",
        "def evaluate( model=None , inp_images=None , annotations=None,inp_images_dir=None ,annotations_dir=None , checkpoints_path=None ):\n",
        "    \n",
        "    if model is None:\n",
        "        assert (checkpoints_path is not None) , \"Please provide the model or the checkpoints_path\"\n",
        "        model = model_from_checkpoint_path(checkpoints_path)\n",
        "        \n",
        "    if inp_images is None:\n",
        "        assert (inp_images_dir is not None) , \"Please privide inp_images or inp_images_dir\"\n",
        "        assert (annotations_dir is not None) , \"Please privide inp_images or inp_images_dir\"\n",
        "        \n",
        "        paths = get_pairs_from_paths(inp_images_dir , annotations_dir )\n",
        "        paths = list(zip(*paths))\n",
        "        inp_images = list(paths[0])\n",
        "        annotations = list(paths[1])\n",
        "        \n",
        "    assert type(inp_images) is list\n",
        "    assert type(annotations) is list\n",
        "        \n",
        "    tp = np.zeros( model.n_classes  )\n",
        "    fp = np.zeros( model.n_classes  )\n",
        "    fn = np.zeros( model.n_classes  )\n",
        "    n_pixels = np.zeros( model.n_classes  )\n",
        "    \n",
        "    for inp , ann   in tqdm( zip( inp_images , annotations )):\n",
        "        pr = predict(model , inp )\n",
        "        gt = get_segmentation_array( ann , model.n_classes ,  model.output_width , model.output_height , no_reshape=True  )\n",
        "        gt = gt.argmax(-1)\n",
        "        pr = pr.flatten()\n",
        "        gt = gt.flatten()\n",
        "                \n",
        "        for cl_i in range(model.n_classes ):\n",
        "            \n",
        "            tp[ cl_i ] += np.sum( (pr == cl_i) * (gt == cl_i) )\n",
        "            fp[ cl_i ] += np.sum( (pr == cl_i) * ((gt != cl_i)) )\n",
        "            fn[ cl_i ] += np.sum( (pr != cl_i) * ((gt == cl_i)) )\n",
        "            n_pixels[ cl_i ] += np.sum( gt == cl_i  )\n",
        "            \n",
        "    cl_wise_score = tp / ( tp + fp + fn + 0.000000000001 )\n",
        "    n_pixels_norm = n_pixels /  np.sum(n_pixels)\n",
        "    frequency_weighted_IU = np.sum(cl_wise_score*n_pixels_norm)\n",
        "    mean_IU = np.mean(cl_wise_score)\n",
        "    return {\"frequency_weighted_IU\":frequency_weighted_IU , \"mean_IU\":mean_IU , \"class_wise_IU\":cl_wise_score }\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zrWEiOx1Wzrd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# source m1 , dest m2\n",
        "def transfer_weights(m1, m2, verbose=True):\n",
        "\n",
        "    assert len(m1.layers) == len(\n",
        "        m2.layers), \"Both models should have same number of layers\"\n",
        "\n",
        "    nSet = 0\n",
        "    nNotSet = 0\n",
        "\n",
        "    if verbose:\n",
        "        print(\"Copying weights \")\n",
        "        bar = tqdm(zip(m1.layers, m2.layers))\n",
        "    else:\n",
        "        bar = zip(m1.layers, m2.layers)\n",
        "\n",
        "    for l, ll in bar:\n",
        "\n",
        "        if not any([w.shape != ww.shape for w, ww in zip(list(l.weights),\n",
        "                                                         list(ll.weights))]):\n",
        "            if len(list(l.weights)) > 0:\n",
        "                ll.set_weights(l.get_weights())\n",
        "                nSet += 1\n",
        "        else:\n",
        "            nNotSet += 1\n",
        "\n",
        "    if verbose:\n",
        "        print(\"Copied weights of %d layers and skipped %d layers\" %\n",
        "              (nSet, nNotSet))\n",
        "\n",
        "\n",
        "def resize_image(inp,  s, data_format):\n",
        "\n",
        "    try:\n",
        "\n",
        "        return Lambda(lambda x: K.resize_images(x,\n",
        "                                                height_factor=s[0],\n",
        "                                                width_factor=s[1],\n",
        "                                                data_format=data_format,\n",
        "                                                interpolation='bilinear'))(inp)\n",
        "\n",
        "    except Exception as e:\n",
        "        # if keras is old, then rely on the tf function\n",
        "        # Sorry theano/cntk users!!!\n",
        "        assert data_format == 'channels_last'\n",
        "        assert IMAGE_ORDERING == 'channels_last'\n",
        "\n",
        "        \n",
        "\n",
        "        return Lambda(\n",
        "            lambda x: tf.image.resize_images(\n",
        "                x, (K.int_shape(x)[1]*s[0], K.int_shape(x)[2]*s[1]))\n",
        "        )(inp)\n",
        "\n",
        "\n",
        "def get_segmentation_model(input, output):\n",
        "\n",
        "    img_input = input\n",
        "    o = output\n",
        "\n",
        "    o_shape = Model(img_input, o).output_shape\n",
        "    i_shape = Model(img_input, o).input_shape\n",
        "\n",
        "    if IMAGE_ORDERING == 'channels_first':\n",
        "        output_height = o_shape[2]\n",
        "        output_width = o_shape[3]\n",
        "        input_height = i_shape[2]\n",
        "        input_width = i_shape[3]\n",
        "        n_classes = o_shape[1]\n",
        "        o = (Reshape((-1, output_height*output_width)))(o)\n",
        "        o = (Permute((2, 1)))(o)\n",
        "    elif IMAGE_ORDERING == 'channels_last':\n",
        "        output_height = o_shape[1]\n",
        "        output_width = o_shape[2]\n",
        "        input_height = i_shape[1]\n",
        "        input_width = i_shape[2]\n",
        "        n_classes = o_shape[3]\n",
        "        o = (Reshape((output_height*output_width, -1)))(o)\n",
        "\n",
        "    o = (Activation('softmax'))(o)\n",
        "    model = Model(img_input, o)\n",
        "    model.output_width = output_width\n",
        "    model.output_height = output_height\n",
        "    model.n_classes = n_classes\n",
        "    model.input_height = input_height\n",
        "    model.input_width = input_width\n",
        "    model.model_name = \"\"\n",
        "\n",
        "    model.train = MethodType(train, model)\n",
        "    model.predict_segmentation = MethodType(predict, model)\n",
        "    model.predict_multiple = MethodType(predict_multiple, model)\n",
        "    model.evaluate_segmentation = MethodType(evaluate, model)\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8JFralwIW540",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Source:\n",
        "# https://github.com/fchollet/deep-learning-models/blob/master/resnet50.py\n",
        "\n",
        "if IMAGE_ORDERING == 'channels_first':\n",
        "    pretrained_url = \"https://github.com/fchollet/deep-learning-models/\" \\\n",
        "                     \"releases/download/v0.2/\" \\\n",
        "                     \"resnet50_weights_th_dim_ordering_th_kernels_notop.h5\"\n",
        "elif IMAGE_ORDERING == 'channels_last':\n",
        "    pretrained_url = \"https://github.com/fchollet/deep-learning-models/\" \\\n",
        "                     \"releases/download/v0.2/\" \\\n",
        "                     \"resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\"\n",
        "\n",
        "\n",
        "def one_side_pad(x):\n",
        "    x = ZeroPadding2D((1, 1), data_format=IMAGE_ORDERING)(x)\n",
        "    if IMAGE_ORDERING == 'channels_first':\n",
        "        x = Lambda(lambda x: x[:, :, :-1, :-1])(x)\n",
        "    elif IMAGE_ORDERING == 'channels_last':\n",
        "        x = Lambda(lambda x: x[:, :-1, :-1, :])(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "def identity_block(input_tensor, kernel_size, filters, stage, block):\n",
        "    \"\"\"The identity block is the block that has no conv layer at shortcut.\n",
        "    # Arguments\n",
        "        input_tensor: input tensor\n",
        "        kernel_size: defualt 3, the kernel size of middle conv layer at\n",
        "                     main path\n",
        "        filters: list of integers, the filterss of 3 conv layer at main path\n",
        "        stage: integer, current stage label, used for generating layer names\n",
        "        block: 'a','b'..., current block label, used for generating layer names\n",
        "    # Returns\n",
        "        Output tensor for the block.\n",
        "    \"\"\"\n",
        "    filters1, filters2, filters3 = filters\n",
        "\n",
        "    if IMAGE_ORDERING == 'channels_last':\n",
        "        bn_axis = 3\n",
        "    else:\n",
        "        bn_axis = 1\n",
        "\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "\n",
        "    x = Conv2D(filters1, (1, 1), data_format=IMAGE_ORDERING,\n",
        "               name=conv_name_base + '2a')(input_tensor)\n",
        "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2a')(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = Conv2D(filters2, kernel_size, data_format=IMAGE_ORDERING,\n",
        "               padding='same', name=conv_name_base + '2b')(x)\n",
        "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2b')(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = Conv2D(filters3, (1, 1), data_format=IMAGE_ORDERING,\n",
        "               name=conv_name_base + '2c')(x)\n",
        "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2c')(x)\n",
        "\n",
        "    x = layers.add([x, input_tensor])\n",
        "    x = Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "def conv_block(input_tensor, kernel_size, filters, stage, block,\n",
        "               strides=(2, 2)):\n",
        "    \"\"\"conv_block is the block that has a conv layer at shortcut\n",
        "    # Arguments\n",
        "        input_tensor: input tensor\n",
        "        kernel_size: defualt 3, the kernel size of middle conv layer at\n",
        "                     main path\n",
        "        filters: list of integers, the filterss of 3 conv layer at main path\n",
        "        stage: integer, current stage label, used for generating layer names\n",
        "        block: 'a','b'..., current block label, used for generating layer names\n",
        "    # Returns\n",
        "        Output tensor for the block.\n",
        "    Note that from stage 3, the first conv layer at main path is with\n",
        "    strides=(2,2) and the shortcut should have strides=(2,2) as well\n",
        "    \"\"\"\n",
        "    filters1, filters2, filters3 = filters\n",
        "\n",
        "    if IMAGE_ORDERING == 'channels_last':\n",
        "        bn_axis = 3\n",
        "    else:\n",
        "        bn_axis = 1\n",
        "\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "\n",
        "    x = Conv2D(filters1, (1, 1), data_format=IMAGE_ORDERING, strides=strides,\n",
        "               name=conv_name_base + '2a')(input_tensor)\n",
        "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2a')(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = Conv2D(filters2, kernel_size, data_format=IMAGE_ORDERING,\n",
        "               padding='same', name=conv_name_base + '2b')(x)\n",
        "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2b')(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = Conv2D(filters3, (1, 1), data_format=IMAGE_ORDERING,\n",
        "               name=conv_name_base + '2c')(x)\n",
        "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2c')(x)\n",
        "\n",
        "    shortcut = Conv2D(filters3, (1, 1), data_format=IMAGE_ORDERING,\n",
        "                      strides=strides, name=conv_name_base + '1')(input_tensor)\n",
        "    shortcut = BatchNormalization(\n",
        "        axis=bn_axis, name=bn_name_base + '1')(shortcut)\n",
        "\n",
        "    x = layers.add([x, shortcut])\n",
        "    x = Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "def get_resnet50_encoder(input_height=224,  input_width=224,\n",
        "                         pretrained='imagenet',\n",
        "                         include_top=True, weights='imagenet',\n",
        "                         input_tensor=None, input_shape=None,\n",
        "                         pooling=None,\n",
        "                         classes=1000):\n",
        "\n",
        "    assert input_height % 32 == 0\n",
        "    assert input_width % 32 == 0\n",
        "\n",
        "    if IMAGE_ORDERING == 'channels_first':\n",
        "        img_input = Input(shape=(3, input_height, input_width))\n",
        "    elif IMAGE_ORDERING == 'channels_last':\n",
        "        img_input = Input(shape=(input_height, input_width, 3))\n",
        "\n",
        "    if IMAGE_ORDERING == 'channels_last':\n",
        "        bn_axis = 3\n",
        "    else:\n",
        "        bn_axis = 1\n",
        "\n",
        "    x = ZeroPadding2D((3, 3), data_format=IMAGE_ORDERING)(img_input)\n",
        "    x = Conv2D(64, (7, 7), data_format=IMAGE_ORDERING,\n",
        "               strides=(2, 2), name='conv1')(x)\n",
        "    f1 = x\n",
        "\n",
        "    x = BatchNormalization(axis=bn_axis, name='bn_conv1')(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = MaxPooling2D((3, 3), data_format=IMAGE_ORDERING, strides=(2, 2))(x)\n",
        "\n",
        "    x = conv_block(x, 3, [64, 64, 256], stage=2, block='a', strides=(1, 1))\n",
        "    x = identity_block(x, 3, [64, 64, 256], stage=2, block='b')\n",
        "    x = identity_block(x, 3, [64, 64, 256], stage=2, block='c')\n",
        "    f2 = one_side_pad(x)\n",
        "\n",
        "    x = conv_block(x, 3, [128, 128, 512], stage=3, block='a')\n",
        "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='b')\n",
        "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='c')\n",
        "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='d')\n",
        "    f3 = x\n",
        "\n",
        "    x = conv_block(x, 3, [256, 256, 1024], stage=4, block='a')\n",
        "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='b')\n",
        "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='c')\n",
        "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='d')\n",
        "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='e')\n",
        "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='f')\n",
        "    f4 = x\n",
        "\n",
        "    x = conv_block(x, 3, [512, 512, 2048], stage=5, block='a')\n",
        "    x = identity_block(x, 3, [512, 512, 2048], stage=5, block='b')\n",
        "    x = identity_block(x, 3, [512, 512, 2048], stage=5, block='c')\n",
        "    f5 = x\n",
        "\n",
        "    x = AveragePooling2D(\n",
        "        (7, 7), data_format=IMAGE_ORDERING, name='avg_pool')(x)\n",
        "    # f6 = x\n",
        "\n",
        "    if pretrained == 'imagenet':\n",
        "        weights_path = keras.utils.get_file(\n",
        "            pretrained_url.split(\"/\")[-1], pretrained_url)\n",
        "        Model(img_input, x).load_weights(weights_path)\n",
        "\n",
        "    return img_input, [f1, f2, f3, f4, f5]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kwI3Ot4rW__M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if IMAGE_ORDERING == 'channels_first':\n",
        "    MERGE_AXIS = 1\n",
        "elif IMAGE_ORDERING == 'channels_last':\n",
        "    MERGE_AXIS = -1\n",
        "\n",
        "\n",
        "def pool_block(feats, pool_factor):\n",
        "\n",
        "    if IMAGE_ORDERING == 'channels_first':\n",
        "        h = K.int_shape(feats)[2]\n",
        "        w = K.int_shape(feats)[3]\n",
        "    elif IMAGE_ORDERING == 'channels_last':\n",
        "        h = K.int_shape(feats)[1]\n",
        "        w = K.int_shape(feats)[2]\n",
        "\n",
        "    pool_size = strides = [\n",
        "        int(np.round(float(h) / pool_factor)),\n",
        "        int(np.round(float(w) / pool_factor))]\n",
        "\n",
        "    x = AveragePooling2D(pool_size, data_format=IMAGE_ORDERING,\n",
        "                         strides=strides, padding='same')(feats)\n",
        "    x = Conv2D(512, (1, 1), data_format=IMAGE_ORDERING,\n",
        "               padding='same', use_bias=False)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = resize_image(x, strides, data_format=IMAGE_ORDERING)\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "def _pspnet(n_classes, encoder,  input_height=384, input_width=576):\n",
        "\n",
        "    assert input_height % 192 == 0\n",
        "    assert input_width % 192 == 0\n",
        "\n",
        "    img_input, levels = encoder(\n",
        "        input_height=input_height,  input_width=input_width)\n",
        "    [f1, f2, f3, f4, f5] = levels\n",
        "\n",
        "    o = f5\n",
        "\n",
        "    pool_factors = [1, 2, 3, 6]\n",
        "    pool_outs = [o]\n",
        "\n",
        "    for p in pool_factors:\n",
        "        pooled = pool_block(o, p)\n",
        "        pool_outs.append(pooled)\n",
        "\n",
        "    o = Concatenate(axis=MERGE_AXIS)(pool_outs)\n",
        "\n",
        "    o = Conv2D(512, (1, 1), data_format=IMAGE_ORDERING, use_bias=False)(o)\n",
        "    o = BatchNormalization()(o)\n",
        "    o = Activation('relu')(o)\n",
        "\n",
        "    o = Conv2D(n_classes, (3, 3), data_format=IMAGE_ORDERING,\n",
        "               padding='same')(o)\n",
        "    o = resize_image(o, (8, 8), data_format=IMAGE_ORDERING)\n",
        "\n",
        "    model = get_segmentation_model(img_input, o)\n",
        "    return model\n",
        "\n",
        "def resnet50_pspnet(n_classes,  input_height=384, input_width=576):\n",
        "\n",
        "    model = _pspnet(n_classes, get_resnet50_encoder,\n",
        "                    input_height=input_height, input_width=input_width)\n",
        "    model.model_name = \"resnet50_pspnet\"\n",
        "    return model\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    m = _pspnet(101, get_resnet50_encoder)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzftor29XDCQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_from_name = {}\n",
        "model_from_name[\"resnet50_pspnet\"] = resnet50_pspnet"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9ImYAHkXOd7",
        "colab_type": "code",
        "outputId": "3009feb2-2439-431d-fb0a-cb6fd4d68044",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tju7Lq-cYKnI",
        "colab_type": "code",
        "outputId": "05bb80aa-aa8f-405f-99c4-57eb13897117",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 925
        }
      },
      "source": [
        "tr_im = \"/content/drive/My Drive/DataSetCityScapes/image_train\"\n",
        "tr_an = \"/content/drive/My Drive/DataSetCityScapes/annotation_train\"\n",
        "val_im = \"/content/drive/My Drive/DataSetCityScapes/image_val\"\n",
        "val_an = \"/content/drive/My Drive/DataSetCityScapes/annotation_val\"\n",
        "check_p = \"/content/drive/My Drive/checkpointsPsPNet/resnet50_pspnet\"\n",
        "\n",
        "load_w = \"/content/drive/My Drive/checkpointsPsPNet/resnet50_pspnet.1\"\n",
        "\n",
        "model = resnet50_pspnet(n_classes=233, input_height=960, input_width=1920)\n",
        "\n",
        "batch_size = 2\n",
        "num_data = 586\n",
        "steps_per_epoch = np.ceil(float(num_data - round(0.2*num_data))/float(batch_size))\n",
        "print(steps_per_epoch)\n",
        "\n",
        "validation_steps = np.ceil(float((round(0.2*num_data)))/float(batch_size))\n",
        "print(validation_steps)\n",
        "\n",
        "num_epochs = 100\n",
        "\n",
        "result = model.train(train_images=tr_im,\n",
        "            train_annotations=tr_an,\n",
        "            checkpoints_path=check_p,\n",
        "            epochs=num_epochs,\n",
        "            batch_size=batch_size,\n",
        "            validate=True,\n",
        "            val_images=val_im,\n",
        "            val_annotations=val_an,\n",
        "            val_batch_size=batch_size,\n",
        "            #auto_resume_checkpoint=True,\n",
        "            #load_weights=\"/content/drive/My Drive/checkpointsPsPNet/resnet50_pspnet.0\",\n",
        "            steps_per_epoch=steps_per_epoch,\n",
        "            validation_steps=validation_steps,\n",
        "            optimizer_name='adam'\n",
        "            )\n",
        "\n",
        "N = len(result.history['loss'])\n",
        "print(N)\n",
        "\n",
        "plt.style.use(\"ggplot\")\n",
        "fig = plt.figure(figsize=(20,8))\n",
        "\n",
        "fig.add_subplot(1,2,1)\n",
        "plt.title(\"Training Loss\")\n",
        "plt.plot(np.arange(0, N), result.history[\"loss\"], label=\"train_loss\")\n",
        "plt.plot(np.arange(0, N), result.history[\"val_loss\"], label=\"val_loss\")\n",
        "plt.ylim(0, 1)\n",
        "\n",
        "fig.add_subplot(1,2,2)\n",
        "plt.title(\"Training Accuracy\")\n",
        "plt.plot(np.arange(0, N), result.history[\"acc\"], label=\"train_accuracy\")\n",
        "plt.plot(np.arange(0, N), result.history[\"val_acc\"],label=\"val_accuracy\")\n",
        "plt.ylim(0, 1)\n",
        "\n",
        "plt.xlabel(\"Epoch #\")\n",
        "plt.ylabel(\"Loss/Accuracy\")\n",
        "plt.legend(loc=\"lower left\")\n",
        "plt.show()\n",
        "\n",
        "out = model.predict_segmentation(\n",
        "    inp=\"/content/drive/My Drive/dataset1/images_prepped_test/0016E5_07965.png\",\n",
        "    out_fname=\"/content/drive/My Drive/tmpPsPNet/out.png\"\n",
        ")\n",
        "\n",
        "plt.imshow(out)\n",
        "\n",
        "print(model.evaluate_segmentation(inp_images_dir=\"/content/drive/My Drive/dataset1/images_prepped_test\",annotations_dir=\"/content/drive/My Drive/dataset1/annotations_prepped_test\"))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "235.0\n",
            "59.0\n",
            "Verifying training dataset\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 586/586 [00:51<00:00, 11.36it/s]\n",
            "  0%|          | 0/267 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Dataset verified! \n",
            "Verifying validation dataset\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 267/267 [00:23<00:00, 11.26it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Dataset verified! \n",
            "Epoch 1/100\n",
            "235/235 [==============================] - 377s 2s/step - loss: 0.7756 - acc: 0.7758 - val_loss: 1.1327 - val_acc: 0.6603\n",
            "\n",
            "Epoch 00001: acc improved from -inf to 0.77585, saving model to /content/drive/My Drive/checkpointsPsPNet/resnet50_pspnet.1\n",
            "Epoch 2/100\n",
            "235/235 [==============================] - 350s 1s/step - loss: 0.5606 - acc: 0.8324 - val_loss: 1.7867 - val_acc: 0.5526\n",
            "\n",
            "Epoch 00002: acc improved from 0.77585 to 0.83238, saving model to /content/drive/My Drive/checkpointsPsPNet/resnet50_pspnet.1\n",
            "Epoch 3/100\n",
            "235/235 [==============================] - 350s 1s/step - loss: 0.4744 - acc: 0.8545 - val_loss: 0.8575 - val_acc: 0.7809\n",
            "\n",
            "Epoch 00003: acc improved from 0.83238 to 0.85447, saving model to /content/drive/My Drive/checkpointsPsPNet/resnet50_pspnet.1\n",
            "Epoch 4/100\n",
            "235/235 [==============================] - 346s 1s/step - loss: 0.4374 - acc: 0.8640 - val_loss: 1.3109 - val_acc: 0.7064\n",
            "\n",
            "Epoch 00004: acc improved from 0.85447 to 0.86401, saving model to /content/drive/My Drive/checkpointsPsPNet/resnet50_pspnet.1\n",
            "Epoch 5/100\n",
            "235/235 [==============================] - 346s 1s/step - loss: 0.3695 - acc: 0.8817 - val_loss: 1.5101 - val_acc: 0.5924\n",
            "\n",
            "Epoch 00005: acc improved from 0.86401 to 0.88173, saving model to /content/drive/My Drive/checkpointsPsPNet/resnet50_pspnet.1\n",
            "Epoch 6/100\n",
            "235/235 [==============================] - 343s 1s/step - loss: 0.3395 - acc: 0.8908 - val_loss: 0.9443 - val_acc: 0.7229\n",
            "\n",
            "Epoch 00006: acc improved from 0.88173 to 0.89082, saving model to /content/drive/My Drive/checkpointsPsPNet/resnet50_pspnet.1\n",
            "Epoch 7/100\n",
            "235/235 [==============================] - 344s 1s/step - loss: 0.3219 - acc: 0.8942 - val_loss: 1.7176 - val_acc: 0.6060\n",
            "\n",
            "Epoch 00007: acc improved from 0.89082 to 0.89424, saving model to /content/drive/My Drive/checkpointsPsPNet/resnet50_pspnet.1\n",
            "Epoch 8/100\n",
            "235/235 [==============================] - 343s 1s/step - loss: 0.3597 - acc: 0.8853 - val_loss: 1.4471 - val_acc: 0.5828\n",
            "\n",
            "Epoch 00008: acc did not improve from 0.89424\n",
            "Epoch 9/100\n",
            "235/235 [==============================] - 341s 1s/step - loss: 0.3196 - acc: 0.8940 - val_loss: 1.0314 - val_acc: 0.7308\n",
            "\n",
            "Epoch 00009: acc did not improve from 0.89424\n",
            "Epoch 10/100\n",
            "235/235 [==============================] - 344s 1s/step - loss: 0.2596 - acc: 0.9127 - val_loss: 0.9868 - val_acc: 0.7501\n",
            "\n",
            "Epoch 00010: acc improved from 0.89424 to 0.91265, saving model to /content/drive/My Drive/checkpointsPsPNet/resnet50_pspnet.1\n",
            "Epoch 11/100\n",
            "220/235 [===========================>..] - ETA: 17s - loss: 0.2411 - acc: 0.9180"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7nRWaESjF2z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorboard --logdir logs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z6GA0PiUaImP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpoints_path=\"/content/drive/My Drive/checkpointsPsPNet/resnet50_pspnet\"\n",
        "input_path=\"/content/drive/My Drive/dataset1/images_prepped_test/0016E5_07965.png\"\n",
        "output_path=\"/content/drive/My Drive/tmpPsPNet/out1.png\"\n",
        "\n",
        "model_config = {\"model_class\": \"resnet50_pspnet\", \"n_classes\": 12, \"input_height\": 576, \"input_width\": 576, \"output_height\": 144, \"output_width\": 144}\n",
        "predict(inp=input_path, out_fname=output_path,checkpoints_path=checkpoints_path)\n",
        "\n",
        "predict_multiple(inp_dir=\"/content/drive/My Drive/CamVid/test\", out_dir=\"/content/drive/My Drive/tmpPsPNet\",checkpoints_path=checkpoints_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "shOH8CxlaVgX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "evaluate(inp_images_dir=\"/content/drive/My Drive/dataset1/images_prepped_test\", annotations_dir=\"/content/drive/My Drive/dataset1/annotations_prepped_test\", checkpoints_path=checkpoints_path)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}